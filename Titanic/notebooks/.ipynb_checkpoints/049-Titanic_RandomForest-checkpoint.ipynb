{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Random Forest to predict Titanic survivors\n",
    "\n",
    "For Random Forest requires floats as input variables (strings need to be converted) and missing data needs to be filled.\n",
    "\n",
    "#### How do I clean and fill?\n",
    "\n",
    "If there is a lot of missing data you will want to try and fill it in. Sometimes that may not be possible, but in others such as Far price could be estimated if you know the class, or Age could be estimated using the median age. \n",
    "\n",
    "#### Data is complete and in floats, let's predict..\n",
    "\n",
    "Three simple steps:    \n",
    "1) Initialize the model    \n",
    "2) Fit it to the training data       \n",
    "3) Predict new values         \n",
    "\n",
    "Nearly all scikit-learn share a few common named functions, once they are initialized. These are:  \n",
    "\n",
    "- modelname.fit()\n",
    "- modelname.predict()\n",
    "- modelname.score()\n",
    "\n",
    "#### Getting started\n",
    "\n",
    "Read in training data with Name, Cabin and Ticket columns removed. Gender and Embarked columns are converted to numbers. \n",
    "Drop PassengerId column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('/home/sophie/projects/Titanic/data/train.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(list(df))\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Gender']\n"
     ]
    }
   ],
   "source": [
    "# Change Gender into 1/0 from sex\n",
    "df['Gender'] = df['Sex'].map({'female': 0, 'male': 1}).astype(float)\n",
    "\n",
    "#Drop columns\n",
    "df = df.drop(['Name','Cabin','Ticket','PassengerId','Sex'], axis=1)\n",
    "\n",
    "print(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass   Age  SibSp  Parch  Fare Embarked  Gender\n",
       "61          1       1  38.0      0      0  80.0      NaN     0.0\n",
       "829         1       1  62.0      0      0  80.0      NaN     0.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there many null values in Embarked?\n",
    "df.isnull().sum()\n",
    "\n",
    "# Print the rows where Embarked is null\n",
    "df[df['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# That is not too many, so we can remove those rows\n",
    "df = df.dropna(subset = ['Embarked'])\n",
    "\n",
    "#This also removes rows with a nan in Embarked column\n",
    "#df = df[pd.notnull(df['Embarked'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Survived, Pclass, Age, SibSp, Parch, Fare, Embarked, Gender]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Check that the nans have been removed\n",
    "print(df[df['Embarked'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3.0\n",
      "1    1.0\n",
      "2    3.0\n",
      "Name: Embarked, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Turn Embarked into float numbers\n",
    "df['Embarked'] = df['Embarked'].map({'C': 1 ,'Q': 2 ,'S': 3}).astype(float)\n",
    "print(df.Embarked[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      int64\n",
       "Pclass        int64\n",
       "Age         float64\n",
       "SibSp         int64\n",
       "Parch         int64\n",
       "Fare        float64\n",
       "Embarked    float64\n",
       "Gender      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What still needs to be turned into a float?\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Embarked      0\n",
       "Gender        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there any columns with nans left?\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still need to fill in the blank values of Age. We could fill them in with the median. Also see what difference it makes using the median, or mean. \n",
    "\n",
    "We will use the median age for each class to fill in.    \n",
    "First, make a table to store the median values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make a table filled with zeros\n",
    "median_ages = np.zeros((2,3)) # male/female for each class\n",
    "median_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35. ,  28. ,  21.5],\n",
       "       [ 40. ,  30. ,  25. ]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop over the table to fill in the values\n",
    "\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        median_ages[i,j] = df[(df['Gender'] == i) & (df['Pclass'] == j + 1)]['Age'].dropna().median()\n",
    "        \n",
    "median_ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a copy of Age \n",
    "df['AgeFill'] = df['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill the new column with the correct values. \n",
    "\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 3):\n",
    "        # we need df.loc here to specify the row AND the column. \n",
    "        # only where age is null, gender is 1/0 and class is 1-3, that AgeFill will be set to the median age.\n",
    "        df.loc[(df.Age.isnull()) & (df.Gender == i) & (df.Pclass == j + 1), 'AgeFill'] = median_ages[i,j]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          0\n",
       "Embarked      0\n",
       "Gender        0\n",
       "AgeFill       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, are there null values still left in AgeFill?\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    float64\n",
       "Pclass      float64\n",
       "SibSp       float64\n",
       "Parch       float64\n",
       "Fare        float64\n",
       "Embarked    float64\n",
       "Gender      float64\n",
       "AgeFill     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can drop the Age column now we have AgeFill\n",
    "df = df.drop(['Age'], axis=1)\n",
    "\n",
    "# This seems to successfully transform the whole dataframe into floats. Perhaps best as the final step?\n",
    "df= df.astype(float)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a data in a format we can use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# One person had 6 Children on board.\n",
    "print(max(df['Parch']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Survived', 'Pclass', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Gender', 'AgeFill']\n",
      "   Pclass  SibSp  Parch     Fare  Embarked  Gender  AgeFill\n",
      "0     3.0    1.0    0.0   7.2500       3.0     1.0     22.0\n",
      "1     1.0    1.0    0.0  71.2833       1.0     0.0     38.0\n",
      "2     3.0    0.0    0.0   7.9250       3.0     0.0     26.0\n",
      "3     1.0    1.0    0.0  53.1000       3.0     0.0     35.0\n",
      "4     3.0    0.0    0.0   8.0500       3.0     1.0     35.0\n"
     ]
    }
   ],
   "source": [
    "print(list(df))\n",
    "print(df.iloc[:,1:][0:5])  df.iloc(rows,columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use the test data, it has to go through the same rigorous process as above. \n",
    "Will put make a script for it and see if it could be used for both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the random forest package\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the random forest object which will include all the parameters for the fit\n",
    "forest = RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the training data to the Survived labels and create the decision trees. (x,y)(train_inputs, classification labels)\n",
    "forest = forest.fit(df.iloc[:,1:], df.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512.329\n",
      "Pclass      float32\n",
      "SibSp       float32\n",
      "Parch       float32\n",
      "Fare        float32\n",
      "Embarked    float32\n",
      "Gender      float32\n",
      "AgeFill     float32\n",
      "dtype: object\n",
      "   Pclass  SibSp  Parch   Fare  Embarked  Gender  AgeFill\n",
      "0     3.0    0.0    0.0   7.83       2.0     1.0     34.5\n",
      "1     3.0    1.0    0.0   7.00       3.0     0.0     47.0\n",
      "2     2.0    0.0    0.0   9.69       2.0     1.0     62.0\n",
      "3     3.0    0.0    0.0   8.66       3.0     1.0     27.0\n",
      "4     3.0    1.0    1.0  12.29       3.0     0.0     22.0\n",
      "     Pclass  SibSp  Parch  Fare  Embarked  Gender  AgeFill\n",
      "0       NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "1       NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "2       NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "3       NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "4       NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "5       NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "6       NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "7       NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "8       NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "9       NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "10      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "11      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "12      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "13      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "14      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "15      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "16      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "17      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "18      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "19      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "20      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "21      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "22      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "23      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "24      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "25      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "26      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "27      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "28      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "29      NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "..      ...    ...    ...   ...       ...     ...      ...\n",
      "388     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "389     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "390     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "391     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "392     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "393     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "394     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "395     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "396     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "397     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "398     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "399     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "400     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "401     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "402     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "403     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "404     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "405     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "406     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "407     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "408     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "409     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "410     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "411     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "412     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "413     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "414     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "415     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "416     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "417     NaN    NaN    NaN   NaN       NaN     NaN      NaN\n",
      "\n",
      "[418 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#Read in the test data which was cleaned up as the training set was in this notebook. The script is\n",
    "# /home/sophie/projects/Titanic/data/clean_test.py\n",
    "test_data = pd.read_csv('/home/sophie/projects/Titanic/data/clean_test.csv', usecols = ['Pclass','SibSp','Parch',\n",
    "                        'Fare','Embarked', 'Gender','AgeFill'], sep = \" \", header=0).astype(np.float32)\n",
    "\n",
    "#test_data = test_data.astype(float)\n",
    "\n",
    "print (max(test_data['Fare']))\n",
    "print(test_data.dtypes)\n",
    "\n",
    "test_data['Fare'] = round(test_data.Fare, 2)\n",
    "print(test_data.head())\n",
    "\n",
    "print(test_data[np.isinf(test_data)])\n",
    "test.isinf().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-164-0a514b4d75e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Take the same decision trees and run it on the test data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/sophie/anaconda2/envs/py3/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \"\"\"\n\u001b[1;32m--> 498\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sophie/anaconda2/envs/py3/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    535\u001b[0m         \"\"\"\n\u001b[0;32m    536\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sophie/anaconda2/envs/py3/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    317\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sophie/anaconda2/envs/py3/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[0;32m    367\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[1;32m/home/sophie/anaconda2/envs/py3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    396\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sophie/anaconda2/envs/py3/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     52\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     53\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 54\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "# Take the same decision trees and run it on the test data.\n",
    "#\n",
    "output = forest.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
